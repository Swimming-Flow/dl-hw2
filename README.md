# CS236781: Deep Learning on Computational Accelerators
# Homework Assignment 2

Faculty of Computer Science, Technion.
## Introduction
In this assignment we'll create a from-scratch implementation of two fundemental deep learning concepts: 
the backpropagation algorithm and stochastic gradient descent-based optimizers. In addition, will create 
a general-purpose multilayer perceptron, the core building block of deep neural networks. We'll visualize 
decision bounrdaries and ROC curves in the context of binary classification. Following that we will focus 
on convolutional networks with residual blocks. We'll use PyTorch to create our own network architectures 
and train them using GPUs on the course servers, and we'll conduct architecture experiments to determine 
the the effects of different architectural decisions on the performance of deep networks.

## Contents

- Part 1: Backpropagation
    - Backpropagation and automatic differentiation:
    - Comparison with PyTorch
    - Layer Implementations
    - Building Models
- Part 2: Optimization and Training:
    - Implementing Optimization Algorithms
    - Vanilla SGD with Regularization
    - Training
    - Momentum
    - RMSProp
    - Dropout Regularization
- Part 3: Binary Classification with Multilayer Perceptrons
    - Synthetic Dataset
    - Simple MLP
    - MLP for Binary Classification
    - Decision Boundary
    - Threshold Selection
    - Architecture Experiments
- Part 4: Convolutional Neural Networks
    - Convolutional layers and networks
    - Building convolutional networks with PyTorch
    - Residual networks
- Part 5: Convolutional Architecture Experiments
    - Experimenting with model architectures
    - Experiment 1: Network depth and number of filters
    - Experiment 2: Custom network architecture
 








